{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wk9SaxOziOk"
   },
   "source": [
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "UGrozEfP-nP1",
    "outputId": "bafae53d-b28a-4375-8bce-f20c9706b950"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 18:44:37.046949 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0824 18:44:37.048954 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0824 18:44:37.050418 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0824 18:44:37.113460 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "  from keras.layers import CuDNNLSTM as LSTM\n",
    "  from keras.layers import CuDNNGRU as GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sf2xeCiFrm5"
   },
   "source": [
    "#We expect our data to be in the the shape NxTxD. N is the number of samples,T is the sequence length and D is vector dimensionality.\n",
    "#With softmax over time, we want to ensure all the outputs in time dimension sum to 1.\n",
    "#So, we exponentiate all values in the input but subtract the max for  numerical stability. Then we divide the sum of exponentials.\n",
    "#We do both operations on axis=1 ,ie, the time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNdMfMem-zkR"
   },
   "outputs": [],
   "source": [
    "\n",
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s\n",
    "\n",
    "\n",
    "\n",
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zn9MTmVf-3Ib",
    "outputId": "73ef24c3-158b-4aeb-d4bd-7b24520a11fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "\n",
    "# load in the data\n",
    "# download the data at: http://www.manythings.org/anki/\n",
    "t = 0\n",
    "for line in open('spa.txt'):\n",
    "  # only keep a limited number of samples\n",
    "  t += 1\n",
    "  if t > NUM_SAMPLES:\n",
    "    break\n",
    "\n",
    "  # input and target are separated by tab\n",
    "  if '\\t' not in line:\n",
    "    continue\n",
    "\n",
    "  # split up the input and translation\n",
    "  input_text, translation = line.rstrip().split('\\t')\n",
    "\n",
    "  # make the target input and output\n",
    "  # recall we'll be using teacher forcing\n",
    "  target_text = translation + ' <eos>'\n",
    "  target_text_input = '<sos> ' + translation\n",
    "\n",
    "  input_texts.append(input_text)\n",
    "  target_texts.append(target_text)\n",
    "  target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idutamhzF1y8"
   },
   "source": [
    "#We are dealing with 2 differerent languages, so we need 2 different vocabularies and two different tokenizers.\n",
    "#So, our first tokenizers work on input and second on targets. \n",
    "#This means we need separte word_index mapping, separate cont for maximum sequence length and separte count fo vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "F3x07g2Q_Ii5",
    "outputId": "d8703ef9-a829-4d48-e4c0-7705a8add160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2342 unique input tokens.\n",
      "Found 6318 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "HhAWpI5W_PWa",
    "outputId": "e9f99dbc-2f23-4c4b-e248-01613ad8ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (10000, 5)\n",
      "encoder_data[0]: [ 0  0  0  0 14]\n",
      "decoder_data[0]: [   2 1466    0    0    0    0    0    0    0]\n",
      "decoder_data.shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "buxRUyQ2_ThO",
    "outputId": "8ffcd152-5dd3-4c9d-fcf7-c9330e0ba1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "6BP5wgsf_ako",
    "outputId": "ecf872fb-f6f4-4491-a208-8337a9b584ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0824 18:44:54.288774 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n",
    "\n",
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    decoder_targets_one_hot[i, t, word] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Qz0et6pGEXM"
   },
   "source": [
    "#the encoder here is bi-directional lstm. It can be changed to GRU, \n",
    "#Set up the first model ---encoder - !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcBD4sJW_hH4"
   },
   "outputs": [],
   "source": [
    "##### build the model #####\n",
    "\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  # dropout=0.5 # dropout not available on gpu\n",
    "))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "\n",
    "# Set up the decoder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQr66AFpGKKi"
   },
   "source": [
    "#Here context vector need to be contacted several times, so we need to put it in a function. We want to the function to use the weight each time,\n",
    "#so we should make the layers global,so that we can use keep reusing the same layers within the function\n",
    "#For the neural net we are using two dense layer. First one uses tanh function and final activation is softmax over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmR1zpB6_lyc"
   },
   "outputs": [],
   "source": [
    "######### Attention #########\n",
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TrAgDnCW_q3s",
    "outputId": "c67c068e-c2d2-434f-b197-b5e4ce5936df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0824 18:45:00.440886 140595988440960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0824 18:45:00.915524 140595988440960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 95s 12ms/step - loss: 2.7094 - acc: 0.6398 - val_loss: 2.6639 - val_acc: 0.6500\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 80s 10ms/step - loss: 2.0509 - acc: 0.7131 - val_loss: 2.4375 - val_acc: 0.6681\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 1.8279 - acc: 0.7309 - val_loss: 2.2821 - val_acc: 0.6807\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 1.6732 - acc: 0.7476 - val_loss: 2.1986 - val_acc: 0.7006\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 1.5419 - acc: 0.7653 - val_loss: 2.0830 - val_acc: 0.7137\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 1.4267 - acc: 0.7774 - val_loss: 2.0217 - val_acc: 0.7236\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 1.3265 - acc: 0.7889 - val_loss: 1.9782 - val_acc: 0.7307\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 90s 11ms/step - loss: 1.2433 - acc: 0.7997 - val_loss: 1.9402 - val_acc: 0.7364\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 1.1693 - acc: 0.8093 - val_loss: 1.9639 - val_acc: 0.7381\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 1.0994 - acc: 0.8186 - val_loss: 1.9440 - val_acc: 0.7432\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 91s 11ms/step - loss: 1.0387 - acc: 0.8267 - val_loss: 1.9212 - val_acc: 0.7467\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.9841 - acc: 0.8348 - val_loss: 1.9314 - val_acc: 0.7442\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.9266 - acc: 0.8428 - val_loss: 1.9260 - val_acc: 0.7468\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.8772 - acc: 0.8498 - val_loss: 1.9411 - val_acc: 0.7472\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.8319 - acc: 0.8565 - val_loss: 1.9398 - val_acc: 0.7459\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 89s 11ms/step - loss: 0.7889 - acc: 0.8626 - val_loss: 1.9495 - val_acc: 0.7439\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.7459 - acc: 0.8690 - val_loss: 1.9366 - val_acc: 0.7442\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.7078 - acc: 0.8745 - val_loss: 1.9296 - val_acc: 0.7454\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.6774 - acc: 0.8799 - val_loss: 1.9626 - val_acc: 0.7419\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.6463 - acc: 0.8858 - val_loss: 1.9655 - val_acc: 0.7407\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 88s 11ms/step - loss: 0.6112 - acc: 0.8905 - val_loss: 1.9611 - val_acc: 0.7443\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.5831 - acc: 0.8942 - val_loss: 1.9939 - val_acc: 0.7413\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.5577 - acc: 0.8980 - val_loss: 2.0005 - val_acc: 0.7387\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 87s 11ms/step - loss: 0.5300 - acc: 0.9028 - val_loss: 2.0158 - val_acc: 0.7366\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 86s 11ms/step - loss: 0.5006 - acc: 0.9073 - val_loss: 2.0177 - val_acc: 0.7366\n"
     ]
    }
   ],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)\n",
    "\n",
    "\n",
    "# Unlike  seq2seq, we cannot get the output\n",
    "# all in one step\n",
    "# Instead we need to do Ty steps\n",
    "# And in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)\n",
    "\n",
    "\n",
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "\n",
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((NUM_SAMPLES, LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "YzTDkAdt_z_e",
    "outputId": "0cbdb098-1325-45f6-9260-9260f223daea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX+//HXSTLpjfSEJITQAiQU\nCb2IbUUWZV0VLKigrmWRddX1q1/XXf361d/63WJbd8WOsoiwdlfFGgWUFiDUQOikQCrphCQz5/fH\nnUBAIAmZzM3MfJ6Px31Mu5n53Ay8c+bcM+corTVCCCHcj5fZBQghhOgaEvBCCOGmJOCFEMJNScAL\nIYSbkoAXQgg3JQEvhBBuSgJeCCHclAS8EEK4KQl4IYRwUz5mvXBUVJROSUkx6+WFEMIlrV+/vkxr\nHd2efU0L+JSUFLKzs816eSGEcElKqQPt3Ve6aIQQwk1JwAshhJuSgBdCCDdlWh+8EMIzNTU1UVBQ\nQENDg9mldGv+/v4kJiZisVjO+Tkk4IUQTlVQUEBISAgpKSkopcwup1vSWlNeXk5BQQG9e/c+5+eR\nLhohhFM1NDQQGRkp4X4WSikiIyM7/SlHAl4I4XQS7m1zxO/I5QJ+5+Eanvx0O/WNzWaXIoQQ3ZrL\nBXzBkXpeWbGPrYXVZpcihHBRwcHBZpfgFC4X8MOSwgHIyT9iciVCCNG9uVzARwb7kRQRQE5+pdml\nCCFcnNaaBx54gPT0dDIyMliyZAkAhw4dYtKkSQwbNoz09HRWrFiB1Wpl9uzZx/d95plnTK6+ba43\nTLKunP8O+IgnD/zc7EqEEJ30P59sY3uRY7tbByWE8ujlg9u17/vvv09OTg6bNm2irKyMkSNHMmnS\nJN5++20uvfRSfv/732O1WqmvrycnJ4fCwkK2bt0KQGVl929kulwLnr1ZTC1fwIV1n1JcLV+UEEKc\nu5UrV3Ldddfh7e1NbGws559/PuvWrWPkyJG88cYbPPbYY2zZsoWQkBBSU1PZu3cv8+bNY9myZYSG\nhppdfptcrwWffhXVqxbwX4VLyN55C7Ejh5pdkRDiHLW3pe1skyZNYvny5Xz66afMnj2b++67j5tu\nuolNmzbxxRdfMH/+fJYuXcrrr79udqln5XoteKXw+8WzWGgm/sdHza5GCOHCJk6cyJIlS7BarZSW\nlrJ8+XJGjRrFgQMHiI2N5Ve/+hW33XYbGzZsoKysDJvNxlVXXcUTTzzBhg0bzC6/Ta7Xggf8Yvqy\nMOg6bjzyFuz8HAZcZnZJQggXdOWVV7Jq1SqGDh2KUoo///nPxMXF8eabb/KXv/wFi8VCcHAwb731\nFoWFhcyZMwebzQbAn/70J5Orb5vSWpvywpmZmbozC348/sFGrsuZRd9wUL9eA36eMa5VCFeXm5vL\nwIEDzS7DJZzud6WUWq+1zmzPz7teF41dRko0DzXeiqoqgO+6/19SIYRwNpcN+GFJPVivB7A76WpY\n/SIc2mR2SUII0a24bMCnRAYSHmhhUcgtEBgBn9wDNqvZZQkhRLfhsgGvlGJoYjiriqww5Sko2gjr\nXjW7LCGE6DZcNuDBmJcmr7iG2n7Toc9F8M3/QlWh2WUJIUS34NoBnxyOTcPmwir4+d/A1gTLHjS7\nLCGE6BbaDHilVJJSKksptV0ptU0pdc9p9pmslKpSSuXYtz92TbknG5bYMrNkJUT0hvMfhNxPYMdn\nznh5IYTo1trTgm8G7tdaDwLGAHOVUoNOs98KrfUw+/a4Q6s8gx5BvqREBpJz0D7pz7h5EDMIPnsA\njtU6owQhhJs729zx+/fvJz093YnVdEybAa+1PqS13mC/XgPkAj27urD2GpYUTk5+JVpr8LbAtGeh\nugCy/p/ZpQkhhKk6NFWBUioFGA6sOc3DY5VSm4Ai4Hda622drq4dhiWF82FOEYeqGkgID4Dk0ZB5\nC6x5EYbMgIRhzihDCHEuPn8IDm9x7HPGZcBlT53x4YceeoikpCTmzp0LwGOPPYaPjw9ZWVkcOXKE\npqYmnnjiCaZPn96hl21oaOCuu+4iOzsbHx8fnn76aS644AK2bdvGnDlzaGxsxGaz8d5775GQkMCM\nGTMoKCjAarXyhz/8gZkzZ3bqsE+n3SdZlVLBwHvAb7XWp07gvAHopbUeCvwd+PAMz3G7UipbKZVd\nWlp6rjWfZHhyD4CTFwC56FEIjJKx8UKIn5g5cyZLly49fnvp0qXcfPPNfPDBB2zYsIGsrCzuv/9+\nOjqNyz/+8Q+UUmzZsoXFixdz880309DQwPz587nnnnvIyckhOzubxMREli1bRkJCAps2bWLr1q1M\nmTLF0YcJtLMFr5SyYIT7Iq31+6c+3jrwtdafKaX+qZSK0lqXnbLfy8DLYMxF06nK7QbGh+Lr40VO\nfiVTM+KNOwPCjb/g794Ca1+BMXc64qWEEI52lpZ2Vxk+fDglJSUUFRVRWlpKjx49iIuL495772X5\n8uV4eXlRWFhIcXExcXFx7X7elStXMm/ePADS0tLo1asXeXl5jB07lieffJKCggJ++ctf0q9fPzIy\nMrj//vt58MEHmTZtGhMnTuySY23PKBoFvAbkaq2fPsM+cfb9UEqNsj9vuSMLPRNfHy8GJ4SeONHa\nYvAvoe/F8K2MjRdCnOyaa67h3XffZcmSJcycOZNFixZRWlrK+vXrycnJITY2loYGxywodP311/Px\nxx8TEBDA1KlT+fbbb+nfvz8bNmwgIyODRx55hMcf75pxKe3pohkP3Ahc2GoY5FSl1J1KqZam8dXA\nVnsf/PPAtdqJ01QOSwpnS2EVzVbbiTuVso+Nt8Ln/+WsUoQQLmDmzJm88847vPvuu1xzzTVUVVUR\nExODxWIhKyuLAwcOdPg5J06cyKJFiwDIy8vj4MGDDBgwgL1795KamspvfvMbpk+fzubNmykqKiIw\nMJBZs2bxwAMPdNnc8m120WitVwKqjX1eAF5wVFEdNSwpnDd+2M/O4hoGJ4SdeKBHCkx+CL5+FHZ8\nCmmyjqsQAgYPHkxNTQ09e/YkPj6eG264gcsvv5yMjAwyMzNJS0vr8HP++te/5q677iIjIwMfHx8W\nLFiAn58fS5cuZeHChVgsFuLi4nj44YdZt24dDzzwAF5eXlgsFl588cUuOEoXng++tYPl9Uz6SxZP\nXpnODaN7nfygtQleOh/qSuDWLyEi1SGvKYQ4NzIffPt57HzwrSVFBBAR5MvGU/vhwRgbf80Co6tm\n4ZVQU+z0+oQQwgxuEfBKqeNfeDqt6P5ww7tQWwr/ugoaqpxboBDCpW3ZsoVhw4adtI0ePdrsstrk\nkmuyns6wpHCydpZQ3dBEqL/lpzskjoCZC+HtGbD4epj1Hlj8nV+oEAKtNfaBdy4hIyODnJwcp76m\nI7rP3aIFD0bAaw2b88/SOu97EVz5EhxYCe/dKl+CEsIE/v7+lJeXOyTA3JXWmvLycvz9O9cIdZsW\n/NCklpkljzChX9SZd8y4GurKjGmF/3MvXP6cMaRSCOEUiYmJFBQU4Khvs7srf39/EhMTO/UcbhPw\nYQEW+kQHnbkfvrUxd0JdKaz4KwRFw0V/6PoChRAAWCwWevfubXYZHsFtAh6Mhbi/zytpX//ehY+c\nHPIynYEQws24TR88GCs8ldU2UnDkaNs7KwU/fxrSphndNZv/3fUFCiGEE7lVwA9ParXCU3t4+8BV\nr0GvCfDhnbDr6y6sTgghnMutAn5AXAh+9pkl283iD9e9DdEDYemNUOCYb9cKIYTZ3CrgLd5eZPQM\n61jAA/iHGePig2Ng0TVQurNrChRCCCdyq4CHEzNLNjbb2t65tZBYuPED8PKBhb+EqoKuKVAIIZzE\n/QI+OZzGZhs7Dp+66FQ7RKTCrHfhWLUR8nVOmdJeCCG6hPsFfEdPtJ4qfihc+zYc2Q//HA0bFoKt\ng58GhBCiG3C7gO8ZHkBUsN9PV3jqiN4T4bavjBb9x3fDaxdDwXrHFSmEEE7gdgHf5syS7RU/FG75\nwpi7pqoAXr0QPpprzEgphBAuwO0CHmB4cjh7y+qoqm/q3BMpBUOvhbuzYdw82PQO/H0ErH4RrM2O\nKVYIIbqIewZ8Sz98QSdb8S38Q+FnT8Bdq4xph5c9BPMnwL7ljnl+IYToAm4Z8BmJYShF5/rhTye6\nP8x6H2YugqY6ePNyWHozVOY79nWEEMIB3DLgQ/wt9IsJJif/iOOfXCkYOA3mroXJD0PeMnhhJHz/\nF2hqcPzrCSHEOXLLgAeOn2jtskUFLAEw+UG4ex30uwSynoB/joGijV3zekII0UFuHPA9OFLfxIHy\n+q59ofBkYynAGz8EWzO8PgW2vNu1rymEEO3gxgHfyS88dVSfC+D276DnCGM5wK8elSUBhRCmctuA\n7x8bTIDF23kBDxAUZbTkM2+BH56FxddCw1nWiBVCiC7ktgHv4+1FRmIYG50Z8AA+vjDtGWMxkT3f\nwisXQdlu59YghBC4ccCDMR4+t6iaY80mdJWMvBVu+giOVsArF8piIkIIp3PrgB+WFE6j1cb2onOY\nWdIRUibAr7KME7FvXwM/PA9dNapHCCFO4d4Bn+zkE62n06MX3PoFDLwCvvoDfHAHNLVjzVghhOgk\ntw74+LAA4kL9zQ14AN8guGYBXPAIbF4Cb0yF6iJzaxJCuD23DnjAMTNLOoJScP4DxlzzZXnw8mTI\nX2d2VUIIN+b+AZ8czoHyeirqGs0uxZD2c7j1K+ObsAumwtpXoLmb1CaEcCvuH/D2Lzxt6g6t+Bax\ng4yTr73GwWe/g2fT4bunoLbE7MqEEG7E7QM+o2cYXgo2HuyCicc6IzACZn1gzE4ZPxS++xM8Mxg+\nuFPmsxFCOISP2QV0tSA/H/rHhjj/C0/t4eUFfS8ytrLdsPZlyFkEmxZD0hgYfYcx+sbb7d8mIUQX\ncPsWPMD5A6L5YXdZ9+qmOVVUX5j6Z7hvO1z6J6g9DO/OgeeGwIqnob7C7AqFEC6mzYBXSiUppbKU\nUtuVUtuUUvecZh+llHpeKbVbKbVZKXVe15R7buZe0JfoED8een8LTVab2eWcnX8YjP01zNsA170D\nkX3hm/+BpwfCx/OgeJvZFQohXER7Pvs3A/drrTcopUKA9Uqpr7TW21vtcxnQz76NBl60X3YLof4W\nHp+ezh0L1/Pqin3cNbmP2SW1zcsbBlxmbMXbYe1LsGkJbHgLEobDgKnGFjvYGIIphHCOYzXG91iq\nC6H6EDRUGlOF26zGpq2tbjeDtp1y2wp9L4ZB07u81DYDXmt9CDhkv16jlMoFegKtA3468JY2VtdY\nrZQKV0rF23+2W7h0cByXDo7l2a/zuCw9jpSoILNLar/YQXD5c3DRo7DxX5D7MWQ9aWzhySfCvtc4\n8LaYXa0Qrqm50Zj9tebQiQA/fr3V1ljTjidT4OVjNNS8fEB526/bb4f36vLDAVAdWfFIKZUCLAfS\ntdbVre7/D/CU1nql/fY3wINa6+wzPVdmZqbOzj7jw12iuLqBi//2PUOSwvjXraNRrtzyrSk2lgvc\n+Rns/Q6aG4zunX4/M8K+78XGYuFCeBprExzaDAXroL4MGuugsdZ+WXeG23Vga/rpcykvCI6D0AQI\njYfQnsb1kAT7fQkQ0MMe5vZAV97GAIouopRar7XObM++7R6eoZQKBt4Dfts63DtY2O3A7QDJycnn\n8hSdEhvqz4OXpfHIh1t5b0MhV49IdHoNDhMSCyNuNrbGOtiTZYR93jLY8m/wskDvifbW/WUQ5sLH\nKsTZHK00wvzgashfAwXZ0Nwy35MC32BjupDjWzAERhmt6FMf8wuBkPgT4R0U49Kj2NrVgldKWYD/\nAF9orZ8+zeMvAd9prRfbb+8EJp+ti8aMFjyAzaaZ8dIqdpfW8vV95xMV7Of0GrqUzQr5a2Hnp7Dj\nM6jYY9wfnQapF0DqZEgZb/xDFsLVaA2VB+DgGshfbYR6SS6gjZZzXAYkj4Xk0ZA02ghrV/6kfhod\nacG3GfDK6Md4E6jQWv/2DPv8HLgbmIpxcvV5rfWosz2vWQEPsKu4hqnPr2BqRjzPXTvclBqcpjQP\n8j43unEO/Gh05Xj5QOJII/D7XAAJ53W8lVJfYfzHKs2F0p3G5u0LEaknb+HJxiIowr3YrFCy3QjY\ngmw4Vm10jVgbjROJp163Ndnvs1+3WcHHz775t7r0P8199svqQiPYaw8bNfiGQNIoSB5jhHnPEeAX\nbO7vxQkcHfATgBXAFqBljOHDQDKA1nq+/Y/AC8AUoB6Yc7b+dzA34AGe+SqP577ZxYI5I5k8IMa0\nOpyqqcH4CLs3y+jSObQJ0OAXCikTjdZ9nwuMoZktrZ76CijdYQ/zlsudUNdqWgXfEIjub/znrdh3\n8kko5QVhST8N/ohUYyplS4ATfwEuwNpkdDkcPWKMzjh6xL5VGiHqFwLBMUbXQbB98w/v+lZqYx0U\nrjcC/eBqo0vkmL2nNjj2RFeGt6/RPdjWdeVl/AFoPmY0Os56ad/8w060zJPHQMwgo8/bwzg04LuK\n2QF/rNnK1OdWcKzZxpf3TiLQ13X72c5ZfQXs+95o3e/JMj76AoQmQkRvY9bL2uIT+/sGQ/QAiB4I\nMWlGt090mtG/3xIwWkNdGVTsPc2255Q1ahWEJ0HUAPvzDrBf72+cuOpumo4aoyhqDhnD41qPsjh6\nxPgdKG8jvJSX/YSb18lb6/uajrYK8Upja9cIjVN4+0JQdKvgj7ZfxhrrBPsGGy1b3+CTr1sCz3wy\nsKb4RBfIwdVGY0BbAQUxA+2t5jHGZXiy23WDdGcS8O20bn8F18xfxW0TevPItEGm1tItVOw9EfbV\nRfbQtYd4TJrREu/sf+T6CqOV3xL4ZXnGJ4KyXWA9dmK/oBh74PdvdZlmhNaxKuN5Wlq6RytOtHTr\nW11vuV9r45OCJcAINR//E9ct/vbLAPCx7+Pta4y+OB7m9uFxDaf5JrRviDG6IjDSuG2zGuOedcul\nDWy2E9db7rdZjToCerTawk9c9w//6f1+IcYY7NpiY2K6utIT12tLjE9Vx6+X2gP5bNSJk46+Qfbg\nDzH+cB3ZZ+zi4290fbQEetLI7vnH14NIwHfAwx9s4Z21B/lo7gQyEsPMLsdz2azGJ4jSPCjbefLl\nsaq2f76FX5gRiIERJwJSeUNTvfGRv+mocb2pwX551Li/se6UQFTGH5PQePuQuPgToytCWobLxXff\nk9U2m/EHrq5lmGCNcXms9pTr9seOX681fmctgR4/VM6hdDMS8B1QdbSJS57+nugQPz6aOx4fb4+Y\nnsd1aG20Ukt3GGFfV3pyq7d1kPuHd25Im7XJHvjHjD8S8qUx0Q11yTh4dxUWYOF/rhjMXYs28NrK\nfdxxvgtMY+BJlIKQOGNLndy1r+VtkVAXbkWaq8CU9DguGRTLM1/ncbC83uxyhBDCISTgAaUUj08f\njI+XF7//cAtmdVsJIYQjScDbxYcF8F9TBrBiVxkfbCw0uxwhhOg0CfhWZo3uxXnJ4fzvf7Z3n0W6\nhRDiHEnAt+LlpXjqqiHUHmvmif9sb/sHhBCiG5OAP0X/2BDuPL8P728sJGtHSds/IIQQ3ZQE/GnM\nvaAvaXEhzFu8ka2FHfiSjRBCdCMS8Kfhb/FmwZxRhAVYuPn1tewrqzO7JCGE6DAJ+DOIC/Nn4a2j\n0MCNr62huLrB7JKEEKJDJODPIjU6mAVzRnKkrpGbXltLVf1plvQSQohuSgK+DUMSw3n5pkz2ldVx\n65vrONrY1gx9QgjRPUjAt8P4vlE8e+0w1h88wty3N9BktbX9Q0IIYTIJ+HaamhHP/05P59sdJTz4\n7mZsNpnOQAjRvXn8bJIdMWtMLyrqGnn6qzwignz5/c8HomQlGyFENyUB30HzLuxLRV0jr67cR2Sw\nH3dNlumFhRDdkwR8Byml+OO0QVTUNfJ/y3YQEWRh5shks8sSQoifkIA/B15eir9eM5TKo0389/tb\nCA/05dLBcWaXJYQQJ5GTrOfI18eL+bPOY0hiOPMWb2TVnnKzSxJCiJNIwHdCoK8Pb8weSXJEIL96\nK1vmrRFCdCsS8J3UI8iXt24ZRai/D7PfWEtecY3ZJQkhBCAB7xAJ4QG8detolFLMeGkVOfmVZpck\nhBAS8I7SNyaY9+4cR6i/hetfWc3KXWVmlySE8HAS8A6UHBnIu3eOJalHILcsWMeyrYfMLkkI4cEk\n4B0sJtSfpXeMJb1nKL9etIEl6w6aXZIQwkNJwHeBsEAL/7ptNBP6RfPge1t46fs9ZpckhPBAEvBd\nJNDXh1dvymTakHj+9PkOnvp8B1rLBGVCCOeRb7J2IV8fL567djihARbmf7+HqqONPPGLDLy9ZIIy\nIUTXk4DvYt5eiid/kU5EoC8vZO2m+mgzT88cip+Pt9mlCSHcnAS8Eyil+N2lAwgPtPDEp7lUNzQx\nf9YIgvzk1y+E6DrSB+9Et01M5S9XD+GH3WXc8OoaKusbzS5JCOHGJOCd7JrMJF6cNYLtRdXMeGkV\nxdUNZpckhHBTEvAmuHRwHAtuGUnhkaP88p8/sq1IJikTQjhemwGvlHpdKVWilNp6hscnK6WqlFI5\n9u2Pji/T/YzrE8WSO8ZitWmufnEVn26Wb70KIRyrPS34BcCUNvZZobUeZt8e73xZniG9ZxgfzxvP\noIRQ5r69gb9+sVMW8xZCOEybAa+1Xg5UOKEWjxQT4s/bvxrNzMwkXsjaze0Ls6lpaDK7LCGEG3BU\nH/xYpdQmpdTnSqnBZ9pJKXW7UipbKZVdWlrqoJd2fX4+3jx1VQaPTx9M1s5Srvznj+wrqzO7LCGE\ni3NEwG8AemmthwJ/Bz48045a65e11pla68zo6GgHvLT7UEpx09gU/nXraMprjzH9hZV8nyd/BIUQ\n567TAa+1rtZa19qvfwZYlFJRna7MQ43tE8nHd08gITyAOW+s5ZXle2UOGyHEOel0wCul4pRSyn59\nlP05ZQXqTkiKCOT9X49jSnocT36Wy31LN9HQZDW7LCGEi2nzu/JKqcXAZCBKKVUAPApYALTW84Gr\ngbuUUs3AUeBaLU3OTgv09eEf15/HC9/u5m9f5bGntJaXbhxBfFiA2aUJIVyEMiuLMzMzdXZ2timv\n7Wq+3HaYe5fkEODrw0s3nseIXhFmlySEMIlSar3WOrM9+8o3WV3AzwbH8cHc8QT5eXPty6tZuGq/\n9MsLIdokAe8i+seG8NHc8YzvG8UfPtrGbW9mU1Z7zOyyhBDdmAS8CwkP9OX1m0fy6OWDWLG7jCnP\nLidrR4nZZQkhuikJeBfj5aWYM743n9w9gahgP+YsWMcfPtzK0UYZZSOEOJkEvIsaEBfCh3PHc9uE\n3ixcfYDLX1jJ1kKZlVIIcYIEvAvzt3jzyLRB/OvW0dQ0NHHlP39g/vd7ZMIyIQQgAe8WJvSLYtk9\nk7goLZanPt/B9a+upqjyqNllCSFMJgHvJnoE+fLirPP481VD2FxQxZRnl/PJpiKzyxJCmEgC3o0o\npZgxMonPfjOR1Ohg5i3eyH1LcmT6YSE8lAS8G0qJCuLfd47lNxf148OcQi57bgVZO2U4pRCeRgLe\nTVm8vbjvkv78+86x+Hp7MeeNddy6YB37ZZ55ITyGBLybG9ErgmW/ncR/X5bG6r3l/OyZ5fzfsh3U\nHWs2uzQhRBeTgPcAvj5e3HF+H7J+N5lpQ+N58bs9XPi37/gop1DmtBHCjUnAe5CYUH+enjGM9+4a\nR0yIP/e8k8OMl1bJF6SEcFMS8B5oRK8efDh3PE/9MoM9pXVc/sJKHv5gCxV1jWaXJoRwIAl4D+Xt\npbh2VDJZv5vM7HEpLFmXzwV//Y63Vu2n2WozuzwhhANIwHu4sAALj14+mM/vmcjghFD++NE2pv19\nJT/uKTO7NCFEJ0nAC8CYb37RbaOZP+s8ahqauf6VNdz0+lq2FEj/vBCuSgJeHKeUYkp6PN/cfz4P\nT01jc0Ell7+wkrv+tZ7dJTVmlyeE6CBZk1WcUU1DE6+u2MdrK/dR39jMlcMT+e3F/UiKCDS7NCE8\nVkfWZJWAF22qqGtk/vd7ePPH/di05rpRydx9QV9iQv3NLk0IjyMBL7rE4aoG/v7tLpasy8fHWzF7\nXG/uPD+V8EBfs0sTwmNIwIsudaC8jme/3sWHOYUE+/pw+6RU5kzoTbCfj9mlCeH2JOCFU+w8XMPf\nvtzJl9uLiQjy5a7z+3DDmGQCfSXohegqEvDCqXLyK/nblztZsauMiCBffjUxlZvG9iJIWvRCOJwE\nvDDF+gMVPP/Nbr7PK6VHoIXb7EEf4m8xuzQh3IYEvDBVTn4lz3+zi293lBDq78OtE1KZPT6FsAAJ\neiE6SwJedAtbCqp4/ttdfLW9mBB/H+aM780t41Nk1I0QnSABL7qVbUVVvPDtbj7fephgPx9uHteL\nWyekEhEkQS9ER0nAi25px+Fq/v7tbj7bcogAizc3ju3FnHG9iQuTL0wJ0V4S8KJb21VcwwtZu/lk\nUxFeSjElPY4541M4L7kHSimzyxOiW5OAFy7hYHk9b63az5LsfGoamsnoGcbN41KYNiQef4u32eUJ\n0S1JwAuXUnesmQ82FvLmj/vZVVJLZJAv141KZtaYXtJ9I8QpJOCFS9Ja8+Oect74YT/f7Cg+0X0z\nLoURvaT7RgjoWMDLVw1Ft6GUYnzfKMb3jeJgeT0LV+9nybp8Pt18iMEJocwel8LlQxOk+0aIdpIW\nvOjW6htPdN/kFdfSI9DCL4b3ZObIJNLiQs0uTwinc2gXjVLqdWAaUKK1Tj/N4wp4DpgK1AOztdYb\n2nphCXjRES3dN2+vOciX2w/TZNUMSQxjRmYSVwxLIFSmQxAewtEBPwmoBd46Q8BPBeZhBPxo4Dmt\n9ei2XlgCXpyrirpGPtxYyNLsfHYcrsHPx4upGfHMyExidO8IvLykr164L4f2wWutlyulUs6yy3SM\n8NfAaqVUuFIqXmt9qF3VCtFBEUG+3DKhN3PGp7ClsIol6/L5OKeIDzYWkhwRyIzMRK4ekSQjcITH\nc8RJ1p5AfqvbBfb7fhLwSqnbgdsBkpOTHfDSwpMppRiSGM6QxHAe+fkglm07xJJ1+fz1yzye/iqP\nSf2jmZmZxEUDY/H1kfXlheeMsBcZAAAMh0lEQVRx6igarfXLwMtgdNE487WFewvw9ebK4YlcOTyR\nA+V1/Du7gHfXF3DXog1EBftyTWYS149KlgXDhUdxRMAXAkmtbifa7xPCFL0ig/jdpQO495L+LM8r\n5e21B3np+z3M/34Pk/pFc8PoZC5Mi8HHW1r1wr05IuA/Bu5WSr2DcZK1SvrfRXfg7aW4IC2GC9Ji\nKKo8ypJ1+byz7iC3L1xPfJg/145MZuZI6asX7qs9o2gWA5OBKKAYeBSwAGit59uHSb4ATMEYJjlH\na93m8BgZRSPM0Gy18c2OEhatOcjyvFK8vRQXD4zhhtG9mNA3SkbgiG5PpioQoh0OlNexeG0+S7Pz\nqahrJDkikOtHJ3PNiEQig/3MLk+I05KAF6IDjjVbWbb1MIvWHGTtvgos3orJA2K4YmgCFw+MJcBX\npkYQ3YfMRSNEB/j5eDN9WE+mD+vJruIa3lmXzyebivhqezGBvt5cMiiW6cMSmNA3WoZbCpciLXgh\nTsNq06zZV84nm4r4bMthqo42ER5o4bL0eK4YmsCo3hF4S3+9MIF00QjhQI3NNlbsKuVje6u+vtFK\nbKgf04YkcMXQBIYkhslUxsJpJOCF6CL1jc18k1vCRzlFfJ9XQpNVkxIZyOVDE5iSHseg+FAJe9Gl\nJOCFcIKq+iaWbTvEx5uKWLWnHJuGpIgApgyOY0p6HMOTesiwS+FwEvBCOFl57TG+zi1m2dbDrNxd\nRpNVEx3ix88GxTIlPY4xqZFY5JuzwgEk4IUwUXVDE1k7Svhi22G+21lKfaOVUH8fLh4Uy6WD45jU\nL1qGXopzJgEvRDfR0GRlxa4ylm09zNe5xVQdbSLA4s3kAdFcOjiOyQOiCQ/0NbtM4UJkHLwQ3YS/\nxRhHf8mgWJqsNtbsrWDZtkN8sa2Yz7cexttLkdmrB5cMiuXigbGkRAWZXbJwI9KCF8IENptmU0El\n3+SW8HVuMTsO1wDQNyaYiwfGcvHAGIYn95Cx9uInpItGCBeTX1HP17nFfJNbwuq95TTbNBFBvlyY\nFsPFA2OZ2C+KID/5wC0k4IVwadUNTXy/s5Svc4vJ2lFCdUMzvj5ejOsTycUDY7loYAzxYQFmlylM\nIgEvhJtostrI3n+Er3OL+Tq3mAPl9QCk9wy1d+XEMjhBvlzlSSTghXBDWmv2lNby1fYSvsktZv3B\nI2gN8WH+RlfOoFjGpkbib5EhmO5MAl4ID1Bee4xvd5TwTW4Jy3cZ4+0Dfb2Z2C+KiwfGcmFajMxr\n74Yk4IXwMA1NVlbvLTe6craXcLi6AaVgeFI4E/tFM6FfFMOSwuXbtG5AAl4ID6a1ZltRtXGSdmcp\nWwoqsWkI9vNhTGoEE/pGMaFfNH2ig6Tv3gVJwAshjquqb+LHPWWs2F3GD7vLjp+ojQ/zt4d9FOP7\nRhEl3TkuQQJeCHFG+RX1rNhVxsrdpfywu5yqo00ADIwPZWK/KMakRjAsqQcRQTKFQnckAS+EaBer\nTbO1sIqVu8tYuauM9QeO0Gi1AZAcEciwpHBjSw5nUHyojNDpBiTghRDnpL6xmc0FVeTkV5JzsJJN\nBZUcqmoAwOKtGBQfytCW0E8Kp3eU9OM7mwS8EMJhiqsb2Hiw0gj9/CNsLqiivtEKQFiAhaFJ4QxP\nCmd4cjjDk3oQFmgxuWL3JgEvhOgyVptmV0nN8Rb+xoOV5BXXYLNHSWp0EOcl9zge+P1jg/GR4ZkO\nIwEvhHCq2mPNbLaH/caDR9h4sJLyukYAAn29GZIYZg/9HgxLCic6REbsnCuZD14I4VTBfj6M6xPF\nuD5RgDEWP7/iKBvzjbDfcPAILy/fS7O9mZ8cEcio3hGMSY1kdO8IkiICzSzfbUkLXgjhFA1NVrYW\nVrHxYCXZBypYu6+CI/XGEM2e4QGMTjUCf0zvSJIiAuTk7RlIF40Qotuz2TR5JTWs2VvB6r3lrNlX\nQYW9WychzJ/RqZGMSY1gdO9IekUGSuDbScALIVyO1ppdJbWs2VvO6r0VrNlXTlmtEfhxof6MSOlB\nRs8wMnqGkZ4Q5rGjdSTghRAur2V65NX2Fv7Gg5UUVh49/nhSRIAR9q1Cv4cHfPtWTrIKIVyeUoq+\nMSH0jQlh1pheABypa2RrURVbCqvYWljF1sJqPtty+PjP9AxvCf1Q0nuGMSghlOhgP4/t3pGAF0K4\njB5BvkzsF83EftHH76uqb2JrkRH4LcG/bNuJ0I8M8iUtPoS0uFDS4kIYGB9K35hgj5h2QQJeCOHS\nwgItjO9rzIjZorqhiW2F1ew4XM2OQzXsOFzNojUHaGgy5tnx9lL0jgo6HvhpcSGkxYeSEObvVq19\nCXghhNsJ9bcwtk8kY/tEHr/PatMcKK9jx+EadhyqJvdwDZsKKvnP5kOtfs6HwQknungGJ4TROyoI\nby/XDH0JeCGER/D2UqRGB5MaHczUjPjj99c0NJFXXEPuoRpyD1Wzraiat1Yd4Fiz0doP9PVmUPyJ\nPv30hDD6xQa7xOpY7Qp4pdQU4DnAG3hVa/3UKY/PBv4CFNrvekFr/aoD6xRCiC4R4m9hRK8IRvSK\nOH5fs9XGntI640RuURXbCqv5d3Y+dfZJ1nx9vEiLC2FwgjGCZ0hiGAPiQrpd6Lc5TFIp5Q3kAZcA\nBcA64Dqt9fZW+8wGMrXWd7f3hWWYpBDCldhsmv3ldWwtqmabPfi3FlYfXzDFz8eLQQmhDE0MZ0hi\nGEMSw0mNCsLLwd07jh4mOQrYrbXea3/yd4DpwPaz/pQQQrgRr1ZdPFcMTQBOzLmzqaCSzQWVbMqv\nYml2Pgt+3A9AiJ8PGfawH5oYxpCkcKeeyG1PwPcE8lvdLgBGn2a/q5RSkzBa+/dqrfNPs48QQrgN\npRTJkYEkRwZyuT30rTbN7pLa46G/uaCK11bupclq9JZEBfty5/l9uG1iapfX56iTrJ8Ai7XWx5RS\ndwBvAheeupNS6nbgdoDk5GQHvbQQQnQf3l6KAXEhDIgLYUZmEgDHmq3kHqo53sp31nTJ7Qn4QiCp\n1e1ETpxMBUBrXd7q5qvAn0/3RFrrl4GXweiD71ClQgjhovx8vI8vc8hY571ue075rgP6KaV6K6V8\ngWuBj1vvoJSKb3XzCiDXcSUKIYQ4F2224LXWzUqpu4EvMIZJvq613qaUehzI1lp/DPxGKXUF0AxU\nALO7sGYhhBDtILNJCiGEC+nIMMnuNSpfCCGEw0jACyGEm5KAF0IINyUBL4QQbkoCXggh3JRpo2iU\nUqXAgXP88SigzIHluBpPPn5PPnbw7OOXYzf00lpHn23nFqYFfGcopbLbO0zIHXny8XvysYNnH78c\ne8ePXbpohBDCTUnACyGEm3LVgH/Z7AJM5snH78nHDp59/HLsHeSSffBCCCHa5qoteCGEEG1wuYBX\nSk1RSu1USu1WSj1kdj3OpJTar5TaopTKUUq5/UxtSqnXlVIlSqmtre6LUEp9pZTaZb/sYWaNXeUM\nx/6YUqrQ/v7nKKWmmlljV1FKJSmlspRS25VS25RS99jv95T3/kzH3+H336W6aNqzALg7U0rtx1jc\n3CPGAtuXgKwF3tJap9vv+zNQobV+yv4HvofW+kEz6+wKZzj2x4BarfVfzaytq9nXl4jXWm9QSoUA\n64FfYExD7gnv/ZmOfwYdfP9drQV/fAFwrXUj0LIAuHBDWuvlGOsLtDYdY0lI7Je/cGpRTnKGY/cI\nWutDWusN9us1GAsI9cRz3vszHX+HuVrAn24B8HM6cBelgS+VUuvt69t6olit9SH79cNArJnFmOBu\npdRmexeOW3ZRtKaUSgGGA2vwwPf+lOOHDr7/rhbwnm6C1vo84DJgrv1jvMfSRv+i6/Qxdt6LQB9g\nGHAI+Ju55XQtpVQw8B7wW611devHPOG9P83xd/j9d7WAb3MBcHemtS60X5YAH2B0WXma4pY1gO2X\nJSbX4zRa62KttVVrbQNewY3ff6WUBSPcFmmt37ff7THv/emO/1zef1cL+DYXAHdXSqkg+wkXlFJB\nwM+ArWf/Kbf0MXCz/frNwEcm1uJUpyxufyVu+v4rpRTwGpCrtX661UMe8d6f6fjP5f13qVE0APah\nQc9yYgHwJ00uySmUUqkYrXYwFkt/292PXSm1GJiMMZNeMfAo8CGwFEjGmI10htba7U5GnuHYJ2N8\nPNfAfuCOVn3SbkMpNQFYAWwBbPa7H8boh/aE9/5Mx38dHXz/XS7ghRBCtI+rddEIIYRoJwl4IYRw\nUxLwQgjhpiTghRDCTUnACyGEm5KAF0IINyUBL4QQbkoCXggh3NT/B1RW0zRaGZEhAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZDT4lVIqyGjwK6VUkNHgV0qpIPP/AZw+Wk4xn5ftAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wR6AHd6_Bnl9"
   },
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "EubMbeuvBniT",
    "outputId": "f2a48931-864e-4c5f-afdc-cf570bee6842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I'm happy.\n",
      "Predicted translation: soy feliz.\n",
      "Actual translation: Soy feliz. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I eat here.\n",
      "Predicted translation: yo como aqu.\n",
      "Actual translation: Como aqu. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Stop them.\n",
      "Predicted translation: los favor hagas a hechos!\n",
      "Actual translation: Prales. <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: Can this wait?\n",
      "Predicted translation: esto puede esperar?\n",
      "Actual translation: Puede esperar esto? <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: I didn't drive.\n",
      "Predicted translation: yo no he mov.\n",
      "Actual translation: Yo no he conducido. <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Attentation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
